{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a85332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850609e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CUDA device: NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "train = r'E:\\MEDICAL PROJECT\\data\\train_split'\n",
    "test = r'E:\\MEDICAL PROJECT\\data\\test'\n",
    "val = r'E:\\MEDICAL PROJECT\\data\\val_split'\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(8),\n",
    "    transforms.ColorJitter(brightness=0.08, contrast=0.08),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(train, transform=train_transform)\n",
    "val_ds   = datasets.ImageFolder(val, transform=val_transform)\n",
    "test_ds  = datasets.ImageFolder(test, transform=val_transform)\n",
    "\n",
    "targets = np.array(train_ds.targets)\n",
    "unique, counts = np.unique(targets, return_counts=True)\n",
    "class_weights = 1.0 / counts\n",
    "sample_weights = class_weights[targets]\n",
    "sample_weights = torch.from_numpy(sample_weights).double()\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds,batch_size=32, sampler= sampler, num_workers= 4,pin_memory= True )\n",
    "val_loader = DataLoader(val_ds,batch_size=32, shuffle= False, num_workers= 4,pin_memory= True )\n",
    "test_loader = DataLoader(test_ds,batch_size=32, shuffle= False, num_workers= 4,pin_memory= True )\n",
    "\n",
    "# Device info\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4b6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b45d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Torch: 2.8.0+cu129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanmay Tomar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tanmay Tomar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  train_loss=0.3352 train_auc=0.9399  val_loss=0.3776 val_auc=0.9816  time=61.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  train_loss=0.2045 train_auc=0.9766  val_loss=0.1731 val_auc=0.9847  time=62.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  train_loss=0.1829 train_auc=0.9803  val_loss=0.1602 val_auc=0.9854  time=60.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  train_loss=0.1888 train_auc=0.9781  val_loss=0.1472 val_auc=0.9874  time=59.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  train_loss=0.1541 train_auc=0.9863  val_loss=0.2422 val_auc=0.9880  time=61.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 1/12  train_loss=0.0961 train_auc=0.9945  val_loss=0.0949 val_auc=0.9981  time=63.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 2/12  train_loss=0.0634 train_auc=0.9974  val_loss=0.0563 val_auc=0.9981  time=63.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 3/12  train_loss=0.0564 train_auc=0.9980  val_loss=0.0434 val_auc=0.9992  time=63.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 4/12  train_loss=0.0347 train_auc=0.9991  val_loss=0.0262 val_auc=0.9995  time=62.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 5/12  train_loss=0.0233 train_auc=0.9996  val_loss=0.0414 val_auc=0.9994  time=62.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 6/12  train_loss=0.0303 train_auc=0.9994  val_loss=0.0943 val_auc=0.9995  time=62.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 7/12  train_loss=0.0341 train_auc=0.9993  val_loss=0.0355 val_auc=0.9997  time=62.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 8/12  train_loss=0.0213 train_auc=0.9996  val_loss=0.0312 val_auc=0.9996  time=62.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 9/12  train_loss=0.0093 train_auc=1.0000  val_loss=0.0196 val_auc=0.9997  time=62.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 10/12  train_loss=0.0092 train_auc=0.9999  val_loss=0.0160 val_auc=0.9998  time=76.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 11/12  train_loss=0.0113 train_auc=0.9998  val_loss=0.0161 val_auc=0.9999  time=124.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Epoch 12/12  train_loss=0.0042 train_auc=1.0000  val_loss=0.0166 val_auc=0.9999  time=121.1s\n",
      "\n",
      "BEST VAL AUC: 0.9998844487241214\n",
      "Saved best model to checkpoints\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "OUT_DIR = \"checkpoints\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "HEAD_EPOCHS = 5\n",
    "FT_EPOCHS = 12\n",
    "BATCH_SIZE = None\n",
    "LR_HEAD = 1e-3\n",
    "LR_FT = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 3\n",
    "MIN_LR = 1e-7\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "\n",
    "def build_model(num_classes = 2):\n",
    "    model = models.resnet18(pretrained = True)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model = build_model(2).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  ### LOSS\n",
    "\n",
    "# Stage 1: freeze backbone except final fc\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "for name, param in model.fc.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "opt_head = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_HEAD, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    opt_head, mode='min', factor=0.5, patience=PATIENCE, min_lr=MIN_LR\n",
    ")\n",
    "\n",
    "def run_epoch(model, loader, optimizer=None, train=False, device=DEVICE, use_amp=False):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    losses = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp and device.type == 'cuda' else None\n",
    "\n",
    "    loop = tqdm(loader, desc='Train' if train else 'EVAL', leave= False)\n",
    "    for imgs, labels in loop:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            if scaler:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(imgs)\n",
    "                    loss = criterion(logits, labels)\n",
    "            else:\n",
    "                logits = model(imgs)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)[:,1].detach().cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "            if train:\n",
    "                if scaler:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loop.set_postfix(loss = np.mean(\n",
    "            \n",
    "        ))\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    return np.mean(losses), auc\n",
    "\n",
    "\n",
    "# TRAINING HELPER: runs stages and save best model by val AUC\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_val_auc = -1.0\n",
    "history = {\"train_loss\":[], \"train_auc\":[], \"val_loss\":[], \"val_auc\":[]}\n",
    "\n",
    "### STAGE - 1 HEAD TRAINING\n",
    "for epoch in range(1,HEAD_EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_auc = run_epoch(model, train_loader, optimizer=opt_head, train=True, use_amp=False)\n",
    "    val_loss, val_auc = run_epoch(model, val_loader, train=False, use_amp=False)\n",
    "    scheduler.step(val_loss)\n",
    "    history[\"train_loss\"].append(train_loss); history[\"train_auc\"].append(train_auc)\n",
    "    history[\"val_loss\"].append(val_loss); history[\"val_auc\"].append(val_auc)\n",
    "\n",
    "    if not np.isnan(val_auc) and val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save({\"model_state\": best_model_wts, \"val_auc\": best_val_auc, \"epoch\": epoch},\n",
    "                    os.path.join(OUT_DIR, f\"best_head_epoch{epoch:.0f}_valauc{val_auc:.4f}.pth\"))\n",
    "\n",
    "    print(f\"Epoch {epoch}/{HEAD_EPOCHS}  train_loss={train_loss:.4f} train_auc={train_auc:.4f}  val_loss={val_loss:.4f} val_auc={val_auc:.4f}  time={(time.time()-t0):.1f}s\")\n",
    "\n",
    "\n",
    "## UNFREEZE BACKBONE AND FINE TUNEEEEEE\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "opt_ft = optim.Adam(model.parameters(), lr=LR_FT, weight_decay=WEIGHT_DECAY)\n",
    "scheduler_ft = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    opt_ft, mode='min', factor=0.5, patience=PATIENCE, min_lr=MIN_LR\n",
    ")\n",
    "\n",
    "for epoch in range(1,FT_EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_auc = run_epoch(model, train_loader, optimizer=opt_ft, train=True, use_amp=False)\n",
    "    val_loss, val_auc = run_epoch(model, val_loader, train=False, use_amp=False)\n",
    "    scheduler_ft.step(val_loss)\n",
    "\n",
    "    if not np.isnan(val_auc) and val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save({\"model_state\": best_model_wts, \"val_auc\": best_val_auc, \"epoch\": HEAD_EPOCHS + epoch},\n",
    "                   os.path.join(OUT_DIR, f\"best_ft_epoch{epoch:.0f}_valauc{val_auc:.4f}.pth\"))\n",
    "\n",
    "    print(f\"FT Epoch {epoch}/{FT_EPOCHS}  train_loss={train_loss:.4f} train_auc={train_auc:.4f}  val_loss={val_loss:.4f} val_auc={val_auc:.4f}  time={(time.time()-t0):.1f}s\")\n",
    "\n",
    "\n",
    "# restore best weights and save final\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save({\"model_state\": model.state_dict(), \"val_auc\": best_val_auc}, os.path.join(OUT_DIR, f\"best_overall_valauc{best_val_auc:.4f}.pth\"))\n",
    "print(\"\\nBEST VAL AUC:\", best_val_auc)\n",
    "print(\"Saved best model to\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2657deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOSS: 0.9909  TEST AUC: 0.9587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Make sure you have your criterion and DEVICE defined\n",
    "ckpt = torch.load(\n",
    "    r\"E:\\MEDICAL PROJECT\\notebooks\\checkpoints\\best_overall_valauc0.9999.pth\",\n",
    "    weights_only=False\n",
    ")\n",
    "\n",
    "model.load_state_dict(ckpt[\"model_state\"])  # pull the correct state dict\n",
    "\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "test_loss, test_auc = run_epoch(model, test_loader, train=False, device=DEVICE, use_amp=False)  \n",
    "print(f\"TEST LOSS: {test_loss:.4f}  TEST AUC: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b86ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDING GRAD CAM TO THIS FOR EXPLAINABILITY\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "        #to store activations and gradients\n",
    "        self.activation = None\n",
    "        self.gradients = None\n",
    "\n",
    "        ##HOOK THE FORWARD AND BACKWARD PASSES\n",
    "        target_layer.register_forward_hook(self.save_activation)\n",
    "        target_layer.register_backward_hook(self.save_gradients)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def save_gradients(slf, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output.detach()\n",
    "\n",
    "    def generate(self, input_tensor, class_idx = None):\n",
    "        \"\"\"\n",
    "        input_tensor: single image tensor [1, C, H, W]\n",
    "        class_idx: class index for which Grad-CAM is computed (default = predicted class)\n",
    "        \"\"\"\n",
    "\n",
    "        #forward pass\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).items()\n",
    "\n",
    "        ##backward pass: get gradients wrt chosen class\n",
    "        self.model.zero_grad()\n",
    "        output[:class_idx].backward()\n",
    "\n",
    "        ### Global average pool gradients -> weights\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "        ###weighted sum of activation\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "\n",
    "        # # Apply ReLU\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        #Normalize\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        cam = (cam - cam.min())/ (cam.max() - cam.min())\n",
    "\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abfe4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img, cam, alpha=0.5):\n",
    "    \"\"\"\n",
    "    img: numpy image (H, W, 3), values in [0, 1]\n",
    "    cam: heatmap (H, W), values in [0, 1]\n",
    "    \"\"\"\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    overlay = np.float32(heatmap) / 255\n",
    "    result = overlay * alpha + img * (1 - alpha)\n",
    "    result = np.clip(result, 0, 1)\n",
    "    plt.imshow(result)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24aa211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanmay Tomar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tanmay Tomar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded! Best Val AUC = 0.9998844487241214\n",
      "✅ Model loaded! Best Val AUC = 0.9998844487241214\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 1. Rebuild the model architecture ---\n",
    "def build_model(num_classes=2):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes=2).to(DEVICE)\n",
    "\n",
    "# --- 2. Load checkpoint ---\n",
    "ckpt_path = r\"E:\\MEDICAL PROJECT\\models\\best_overall_valauc0.9999.pth\"  # update if needed\n",
    "ckpt = torch.load(ckpt_path, map_location=DEVICE, weights_only=False)\n",
    "\n",
    "# your weights are stored under the \"model_state\" key\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "print(\"✅ Model loaded! Best Val AUC =\", ckpt.get(\"val_auc\", \"unknown\"))\n",
    "\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ Model loaded! Best Val AUC =\", ckpt.get(\"val_auc\", \"unknown\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afeeb639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanmay Tomar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1864: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m img_np = np.clip(img_np, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# ---- Run Grad-CAM ----\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m cam = \u001b[43mgradcam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ---- Show result ----\u001b[39;00m\n\u001b[32m     23\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m,\u001b[32m4\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mGradCAM.generate\u001b[39m\u001b[34m(self, input_tensor, class_idx)\u001b[39m\n\u001b[32m     34\u001b[39m output = \u001b[38;5;28mself\u001b[39m.model(input_tensor)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m class_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     class_idx = \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m()\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m##backward pass: get gradients wrt chosen class\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mself\u001b[39m.model.zero_grad()\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Make sure model is loaded & in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Init Grad-CAM with last conv block of ResNet18\n",
    "gradcam = GradCAM(model, model.layer4[-1])\n",
    "\n",
    "# ---- Pick one batch from validation/test ----\n",
    "images, labels = next(iter(val_loader))   # or test_loader\n",
    "img_tensor = images[0].unsqueeze(0).to(DEVICE)  # single image\n",
    "label = labels[0].item()\n",
    "\n",
    "# Save original image (for overlay)\n",
    "# Undo normalization for visualization\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std  = np.array([0.229, 0.224, 0.225])\n",
    "img_np = images[0].permute(1, 2, 0).numpy() * std + mean\n",
    "img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "# ---- Run Grad-CAM ----\n",
    "cam = gradcam.generate(img_tensor)\n",
    "\n",
    "# ---- Show result ----\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_np)\n",
    "plt.title(f\"Original (Label={label})\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "show_cam_on_image(img_np, cam)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531543f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
